#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Solves Laplace equation over the domain of white matter.

Using grey matter as the source and ventricles as the sink.
Inputs are expected to be Free/FastSurfer aparc+aseg.mgz in .nii.gz format

Parameters
----------
NIFTI  :    str
            Parcellation file generated by Freesurfer/fastsurfre in nii.gz format (from mri/aparc+aseg.mgz).
NIFTI  :    str
            Output laplacian file path (nii.gz)

Returns
-------
NIFTI
    Laplacian image (nii.gz)

Usage
-----
laplace_solver.py aparc+aseg.nii.gz laplace-wm.nii.gz

Created on October 2023

@author: Jordan DeKraker
code from https://github.com/khanlab/hippunfold/blob/master/hippunfold/workflow/scripts/laplace_coords.py

"""

import nibabel as nib
import numpy as np
import skfmm
from scipy.ndimage import binary_dilation, convolve
import sys
from time import time

# Replace slow astropy convolve with fast scipy implementation
def fast_convolve(data, kernel):
    """Fast convolution that handles NaN values efficiently."""
    # Create mask for NaN values
    nan_mask = np.isnan(data)
    
    if np.any(nan_mask):
        # Replace NaNs with zeros for convolution
        data_filled = np.copy(data)
        data_filled[nan_mask] = 0.0
        
        # Convolve data and create weight map
        result = convolve(data_filled, kernel, mode='constant', cval=0.0)
        weights = convolve((~nan_mask).astype(np.float32), kernel, mode='constant', cval=0.0)
        
        # Normalize by weights where weights > 0
        valid_weights = weights > 1e-10
        result[valid_weights] /= weights[valid_weights]
        result[~valid_weights] = np.nan
        
        return result
    else:
        # No NaNs, use regular convolution
        return convolve(data, kernel, mode='constant', cval=0.0)


def _get_bounding_box(mask, padding=1):
    """Get tight bounding box around mask with padding."""
    coords = np.where(mask)
    if len(coords[0]) == 0:
        return (0, 0, 0), mask.shape
    
    min_coords = np.maximum(0, [np.min(c) - padding for c in coords])
    max_coords = np.minimum(mask.shape, [np.max(c) + padding + 1 for c in coords])
    
    return tuple(min_coords), tuple(max_coords)


def _crop(x, min_bbox, max_bbox):
    """Crop array using bounding box."""
    return x[min_bbox[0]:max_bbox[0], min_bbox[1]:max_bbox[1], min_bbox[2]:max_bbox[2]]


def laplace(
    init_coords,
    fg,
    source,
    sink,
    kernelSize=3,
    convergence_threshold=1e-4,
    max_iters=500,
    initial_lr=1,
    lr_decay=0.995,
    verbose=False
):
    """
    Solve Laplace equation using optimized iterative convolution.
    
    Parameters:
    -----------
    init_coords : ndarray
        Initial solution coordinates
    fg : ndarray (boolean)
        Foreground mask
    source : ndarray (boolean)
        Source mask (boundary condition = 0)
    sink : ndarray (boolean)
        Sink mask (boundary condition = 1)
    kernelSize : int, default=3
        Size of convolution kernel
    convergence_threshold : float, default=1e-6
        Threshold for convergence
    max_iters : int, default=500
        Maximum number of iterations
    initial_lr : float, default=0.5
        Initial learning rate
    lr_decay : float, default=0.999
        Learning rate decay factor
    verbose : bool, default=False
        Print progress information
    
    Returns:
    --------
    ndarray
        Solution to the Laplace equation
    """
    start_time = time()
    
    # Pre-compute normalized kernel
    hl = np.ones([kernelSize, kernelSize, kernelSize], dtype=np.float32)
    hl = hl / np.sum(hl)
    
    # Use float32 for better performance
    coords = np.zeros(init_coords.shape, dtype=np.float32)
    coords[fg] = init_coords[fg].astype(np.float32)
    coords[source] = 0.0
    coords[sink] = 1.0
    
    # Pre-compute masks for efficiency
    update_mask = fg & ~source & ~sink
    n_update = np.sum(update_mask)
    
    if verbose:
        print(f"Initialized solution with {n_update} voxels to update")
    
    # Initialize learning rate and convergence tracking
    lr = initial_lr
    last_ssd = np.inf
    min_improvement = convergence_threshold * 0.01
    stagnation_count = 0
    
    # Pre-allocate arrays
    coords_new = np.copy(coords)
    
    for i in range(max_iters):
        # Fast convolution
        upd_coords = fast_convolve(coords, hl)
        
        # Vectorized update with learning rate
        coords_new[update_mask] = (coords[update_mask] * (1 - lr) + 
                                  upd_coords[update_mask] * lr)
        
        # Enforce boundary conditions
        coords_new[source] = 0.0
        coords_new[sink] = 1.0
        
        # Calculate convergence metric (only on update regions)
        diff = coords[update_mask] - coords_new[update_mask]
        ssd = np.sum(diff * diff)
        
        # Update learning rate
        lr *= lr_decay
        
        # Progress reporting (less frequent to reduce overhead)
        if verbose and (i < 5 or i % 20 == 0):
            elapsed = time() - start_time
            print(f"iteration {i}, ssd: {ssd:.8e}, lr: {lr:.6f}, time: {elapsed:.2f}s")
        
        # Check for stagnation
        improvement = abs(last_ssd - ssd) / max(last_ssd, 1e-10)
        if improvement < min_improvement:
            stagnation_count += 1
            if stagnation_count >= 5:
                if verbose:
                    print(f"Early stopping at iteration {i}: stagnation detected")
                break
        else:
            stagnation_count = 0
        
        last_ssd = ssd
        
        # Check convergence
        if ssd < convergence_threshold:
            if verbose:
                print(f"Converged at iteration {i}")
            break
        
        # Swap arrays (avoid copying)
        coords, coords_new = coords_new, coords
    
    if verbose:
        print(f"Laplace solver completed in {time() - start_time:.2f}s")
    
    return coords


def solve_laplace(
    in_seg,
    out_laplace,
    convergence_threshold=1e-4,
    max_iters=500,
    kernelSize=3,
    alpha=0.1,
    initial_lr=0.5,
    lr_decay=0.999,
    fg_labels=[41, 2],
    src_labels=np.concatenate((np.arange(1000, 2999), [0])),
    verbose=True
):
    """Solve Laplace equation with optimizations."""
    total_start = time()
    
    if verbose:
        print("Starting optimized Laplace solver")
    
    # Efficient data loading
    lbl_nib = nib.load(in_seg)
    lbl = np.asarray(lbl_nib.dataobj, dtype=np.int16)  # Use int16 to save memory
    
    if verbose:
        print(f"Loaded data: {time() - total_start:.2f}s")
    
    # Vectorized mask creation
    fg = np.isin(lbl, fg_labels)
    fg = binary_dilation(fg, iterations=1)  # Single iteration is usually sufficient
    source = np.isin(lbl, src_labels)
    source = source & ~fg  # Remove overlap with foreground
    sink = ~(fg | source)
    
    if verbose:
        print(f"Created masks: {time() - total_start:.2f}s")
        print(f"Foreground: {np.sum(fg)} voxels")
        print(f"Source: {np.sum(source)} voxels") 
        print(f"Sink: {np.sum(sink)} voxels")
    
    # Fast marching initialization
    phi = np.ones_like(lbl, dtype=np.float32)
    phi[source] = 0.0
    
    # Create efficient mask for fast marching
    mask = ~(fg | source)
    phi_masked = np.ma.MaskedArray(phi, mask)
    
    fmm_start = time()
    forward = skfmm.travel_time(phi_masked, np.ones_like(lbl, dtype=np.float32))
    
    # Efficient normalization
    init_coords = forward.data
    finite_mask = np.isfinite(init_coords)
    if np.any(finite_mask):
        min_val = np.min(init_coords[finite_mask])
        max_val = np.max(init_coords[finite_mask])
        if max_val > min_val:
            init_coords = (init_coords - min_val) / (max_val - min_val)
        else:
            init_coords.fill(0)
    init_coords[fg] = 0.0
    
    if verbose:
        print(f"Fast marching: {time() - fmm_start:.2f}s")
    
    # Work on tightly cropped region
    min_bbox, max_bbox = _get_bounding_box(fg, padding=kernelSize)
    crop_volume = np.prod([max_bbox[i] - min_bbox[i] for i in range(3)])
    total_volume = np.prod(lbl.shape)
    
    if verbose:
        print(f"Cropping to {crop_volume/total_volume:.1%} of original volume")
    
    # Crop all arrays
    cropped_init = _crop(init_coords, min_bbox, max_bbox)
    cropped_fg = _crop(fg, min_bbox, max_bbox)
    cropped_source = _crop(source, min_bbox, max_bbox)
    cropped_sink = _crop(sink, min_bbox, max_bbox)
    
    solve_start = time()
    
    # Solve on cropped domain
    cropped_coords = laplace(
        cropped_init,
        cropped_fg,
        cropped_source,
        cropped_sink,
        kernelSize=kernelSize,
        convergence_threshold=convergence_threshold,
        max_iters=max_iters,
        initial_lr=initial_lr,
        lr_decay=lr_decay,
        verbose=verbose
    )
    
    if verbose:
        print(f"Solved Laplace equation: {time() - solve_start:.2f}s")
    
    # Reconstruct full-size result
    coords = np.zeros_like(init_coords, dtype=np.float32)
    coords[min_bbox[0]:max_bbox[0], 
           min_bbox[1]:max_bbox[1], 
           min_bbox[2]:max_bbox[2]] = cropped_coords
    
    # Apply boundary conditions
    coords[source] = 0.0
    coords[sink] = 1.0
    
    # Blend with initial solution if needed
    if alpha > 0:
        coords = coords * (1 - alpha) + init_coords * alpha
    
    # Save efficiently
    save_start = time()
    coords_nib = nib.Nifti1Image(coords, lbl_nib.affine, lbl_nib.header)
    coords_nib.set_data_dtype(np.float32)
    nib.save(coords_nib, out_laplace)
    
    if verbose:
        print(f"Saved result: {time() - save_start:.2f}s")
        print(f"Total time: {time() - total_start:.2f}s")


if __name__ == "__main__":
    in_seg = sys.argv[1]
    out_laplace = sys.argv[2]
    solve_laplace(in_seg, out_laplace)
